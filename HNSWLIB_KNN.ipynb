{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to build our own vector database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## different ANN Algorithms\n",
    "\n",
    "###  1. HNSWBLIB ( Proximity Graph)\n",
    "### 2. Google ScaNN (Vector Compression)\n",
    "### 3. spotify annoy (trees)\n",
    "### 4. Faiss (clustering )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNSWLIB\n",
    "\n",
    "# Hierarichal navigable small world\n",
    "# it is graph based algorithm\n",
    "# it is used for effecient proximate nearest neighbors (ANN)\n",
    "# it search in high dimensional space \n",
    "# very popular for its performance in terms of speed and accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: hnswlib in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (0.8.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (4.36.1)\n",
      "Requirement already satisfied: tqdm in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: scipy in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sentence_transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nirbhaysedha/Documents/local_Env/env/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [\n",
    "    \"Implementing a basic neural network using TensorFlow for image classification.\",\n",
    "    \"Exploring the power of convolutional neural networks in computer vision tasks.\",\n",
    "    \"Understanding recurrent neural networks and their application in sequential data analysis.\",\n",
    "    \"Optimizing model performance through hyperparameter tuning and regularization techniques.\",\n",
    "    \"Utilizing transfer learning with pre-trained models for faster convergence and improved accuracy.\",\n",
    "    \"Implementing a generative adversarial network (GAN) for synthetic data generation.\",\n",
    "    \"Applying natural language processing techniques using recurrent neural networks for text generation.\",\n",
    "    \"Visualizing and interpreting deep learning models' intermediate layers for better insights.\",\n",
    "    \"Deploying deep learning models on edge devices for real-time inference.\",\n",
    "    \"Exploring ethical considerations and biases in deep learning algorithms and data.\"\n",
    "]\n",
    "# replace this code with pdf loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## geenerate embeddings \n",
    "embeddings = model.encode(paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=embeddings.shape[1]\n",
    "# no of columns in embedding vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim # embeddings dimesnions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize the hnswblib index\n",
    "\n",
    "index=hnswlib.Index(space='l2',dim=dim)\n",
    "# in space we can put l2 , ip , cosine \n",
    "# l2 euclidean distance \n",
    "# thes parameters help for calculating nearest embedding in vector space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_elements=len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing index\n",
    "index.init_index(max_elements=num_of_elements, ef_construction=200, M=16)\n",
    "# max_elements maximum no of embeddings index can hold\n",
    "# ef_construction and M controls the construction of the index and for used for \n",
    "# the speed of retreival this means how fast your retriever is \n",
    "\n",
    "# max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add embeddings into the index\n",
    "\n",
    "index.add_items(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## querying the index\n",
    "\n",
    "query_sentence=\"\"\"what techniques are used to perform the Optimizing model performance\"\"\" # creating doc strings for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings=model.encode([query_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4]], dtype=uint64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## query the index\n",
    "n_nearet_neighbor=2\n",
    "# 2 nearest neighbours\n",
    "labels,distances=index.knn_query(query_embeddings,k=n_nearet_neighbor)\n",
    "# performing k nearesr neighbour \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query  :-    what techniques are used to perform the Optimizing model performance\n",
      "paragraph Optimizing model performance through hyperparameter tuning and regularization techniques. distances 0.5769592523574829\n",
      "paragraph Utilizing transfer learning with pre-trained models for faster convergence and improved accuracy. distances 1.2515884637832642\n"
     ]
    }
   ],
   "source": [
    "print(f\"query  :-    {query_sentence}\")\n",
    "for label,distance in zip(labels[0],distances[0]):\n",
    "    print(f\"paragraph {paragraphs[label]} distances {distance}\")\n",
    "    # here distances shows how much the embeddidngs are nearer as we have taken k as 2 so we got nearest 2 embeddings\n",
    "    # using euclidean distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulst interpretation \n",
    "# lower distance = closer match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
